<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="description" content="smoothscale">
<title>Statistical Models used for Smoothing and Scaling • smoothscale</title>
<script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- bootstrap-toc --><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@v1.0.1/dist/bootstrap-toc.min.js" integrity="sha256-4veVQbu7//Lk5TSmc7YV48MxtMy98e26cf5MrgZYnwo=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- search --><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Statistical Models used for Smoothing and Scaling">
<meta property="og:description" content="smoothscale">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>
    

    <nav class="navbar fixed-top navbar-light navbar-expand-lg bg-light"><div class="container">
    
    <a class="navbar-brand me-2" href="../index.html">smoothscale</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">0.1.0</small>

    
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item">
  <a class="nav-link" href="../reference/index.html">Reference</a>
</li>
<li class="active nav-item dropdown">
  <a href="#" class="nav-link dropdown-toggle" data-bs-toggle="dropdown" role="button" aria-expanded="false" aria-haspopup="true" id="dropdown-articles">Articles</a>
  <div class="dropdown-menu" aria-labelledby="dropdown-articles">
    <a class="dropdown-item" href="../articles/smoothscale-models.html">Statistical Models used for Smoothing and Scaling</a>
    <a class="dropdown-item" href="../articles/smoothscale-using.html">Using Package 'smoothscale'</a>
  </div>
</li>
      </ul>
<form class="form-inline my-2 my-lg-0" role="search">
        <input type="search" class="form-control me-sm-2" aria-label="Toggle navigation" name="search-input" data-search-index="../search.json" id="search-input" placeholder="Search for" autocomplete="off">
</form>

      <ul class="navbar-nav"></ul>
</div>

    
  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">
      <img src="" class="logo" alt=""><h1>Statistical Models used for Smoothing and Scaling</h1>
            
      
      
      <div class="d-none name"><code>smoothscale-models.Rmd</code></div>
    </div>

    
    
<div class="section level2">
<h2 id="introduction">Introduction<a class="anchor" aria-label="anchor" href="#introduction"></a>
</h2>
<p>The <strong>smoothscale</strong> package provides functions for
estimating counts and prevalences in small populations. The functions
deal with two of the problems that often arise when doing this sort of
estimation: sampling errors and measurement errors. Statisticans have
developed many methods for estimation in small populations, under the
headings of “small area estimation” <span class="citation">(Rao and
Molina 2015)</span>. Many of these methods are complex, and require
specialist statistical skills. The methods used in
<strong>smoothscale</strong> are, in contrast, deliberately simple.</p>
<p>This vignette defines sampling and measurement errors, and describes
how they are dealt with by functions in <strong>smoothscale</strong>.
The vignette then discusses two further issues: stratification by
additional variables such as age and sex/gender, and interactions
between sampling and measurement errors.</p>
</div>
<div class="section level2">
<h2 id="sampling-errors">Sampling Errors<a class="anchor" aria-label="anchor" href="#sampling-errors"></a>
</h2>
<div class="section level3">
<h3 id="the-setting">The setting<a class="anchor" aria-label="anchor" href="#the-setting"></a>
</h3>
<p>We would like to estimate the prevalence of some attribute, such as
employment or school attendance, in each of <span class="math inline">\(k = 1, \dots, K\)</span> small areas. We are
interested in absolute numbers and in underlying probabilities.</p>
<p>We have data on <span class="math inline">\(n_k\)</span> people from
each area. The number of people in each area who are reported to have
the attribute in question is <span class="math inline">\(x_k\)</span>.
In the following hypothetical data, for instance, <span class="math inline">\(n_k\)</span> is the number of respondents in each
distribution, and <span class="math inline">\(x_k\)</span> is the number
of respondents who attend school:</p>
<table class="table">
<thead><tr class="header">
<th align="left">District</th>
<th align="center">Respondents</th>
<th align="center">Respondents attending school</th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="left">1001</td>
<td align="center">83</td>
<td align="center">62</td>
</tr>
<tr class="even">
<td align="left">1002</td>
<td align="center">25</td>
<td align="center">18</td>
</tr>
<tr class="odd">
<td align="left"><span class="math inline">\(\vdots\)</span></td>
<td align="center"><span class="math inline">\(\vdots\)</span></td>
<td align="center"><span class="math inline">\(\vdots\)</span></td>
</tr>
<tr class="even">
<td align="left">1156</td>
<td align="center">54</td>
<td align="center">41</td>
</tr>
</tbody>
</table>
<p>If the data come from a census or administrative system, then the
number of repondents may be approximately equal to size of the target
population in each area. The number of children captured in the census,
for instance, should be close to the actual number of children living in
an area.</p>
<p>If, however, the data come from a sample extracted from the census,
then the number of respondents is likely to be much smaller than the
number of people in the target population. In this case, to estimate
counts of people with the attribute in each area, we need an additional
set of data, <span class="math inline">\(N_k\)</span>, <span class="math inline">\(k = 1, \cdots, K\)</span>, on the size of the
target population in each area. Data on a target population of
school-age children, for instance, might look like this:</p>
<table class="table">
<thead><tr class="header">
<th align="left">District</th>
<th align="center">Total school-age children</th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="left">1001</td>
<td align="center">8301</td>
</tr>
<tr class="even">
<td align="left">1002</td>
<td align="center">2500</td>
</tr>
<tr class="odd">
<td align="left"><span class="math inline">\(\vdots\)</span></td>
<td align="center"><span class="math inline">\(\vdots\)</span></td>
</tr>
<tr class="even">
<td align="left">1156</td>
<td align="center">5402</td>
</tr>
</tbody>
</table>
<p>Observed prevalences always, to some extent, reflect random
variation. Whether a particular child is involved in child labour, for
instance, depends partly on random factors such as the economic status
of the child’s family. If the data come from a survey, then the sample
selection procedures add further randomness. We can therefore think of
the number of people with the attribute as reflecting</p>
<ol style="list-style-type: decimal">
<li>a stable ‘expected’ value, and</li>
<li>random error.</li>
</ol>
<p>Similarly, the proportion of people in an area who have an attribute
reflects</p>
<ol style="list-style-type: decimal">
<li>an underlying propensity to have the attribute, and</li>
<li>random error.</li>
</ol>
<p>In small populations, it can be essential to distinguish between an
observed proportion and an underlyign propensity. Consider, for
instance, a population of 10 people in which, during a given yer, no one
dies. The observed proportion of people dying for that year is zero.
However the underlying propensity – the risk of dying that people in
fact faced during the year – was not zero.</p>
<p>In large populations, random errors tend to cancel out, so that
observed counts can be reliable indicators of underlying propensities.
In small populations, there is much less scope for cancellation, so that
observed counts are much more noisy. The statistical challenge is to
minimise the effects of the noise, and to get at the underlying expected
values and propensities.</p>
</div>
<div class="section level3">
<h3 id="statistical-model">Statistical model<a class="anchor" aria-label="anchor" href="#statistical-model"></a>
</h3>
<p>Function <code><a href="../reference/smooth_prob.html">smooth_prob()</a></code> produces smoothed estimates that
try to strip out the effects of random variation. The model draws on
ideas from Bayesian statistics <span class="citation">(Gelman et al.
2014)</span>, but in contrast to a fully Bayesian analysis,
<code><a href="../reference/smooth_prob.html">smooth_prob()</a></code> only yields point estimates.</p>
<p>The estimates are based on a statistical model. The number of people
in area <span class="math inline">\(k\)</span> with the attribute of
interest is treated as a random draw from a binomial distribution, <span class="math display">\[\begin{equation}
  x_k \sim \text{Binomial}(n_k, \pi_k),
\end{equation}\]</span> where <span class="math inline">\(\pi_k\)</span>
is the probability of having the attribute. The job of
<code><a href="../reference/smooth_prob.html">smooth_prob()</a></code> is to estimate <span class="math inline">\(\pi_k\)</span> for all <span class="math inline">\(K\)</span> areas.</p>
<p>Function <code><a href="../reference/smooth_prob.html">smooth_prob()</a></code> assumes that the <span class="math inline">\(\pi_k\)</span> come from a beta distribution,
<span class="math display">\[\begin{equation}
  \pi_k \sim \text{Beta}(\alpha, \beta).
\end{equation}\]</span> The centre of this distribution, and the extent
to which the values concentrate around the centre, are determined by
parameters <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span>. Values for these parameters are
estimated from the data.</p>
<p>Rather than work directly with <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span>, we express them in terms of two
new parameters, <span class="math display">\[\begin{align}
  \alpha &amp; = \lambda \nu \\
  \beta &amp; = (1 - \lambda) \nu
\end{align}\]</span> Parameter <span class="math inline">\(\lambda\)</span> is the central value for <span class="math inline">\(\pi_k\)</span>, and parameter <span class="math inline">\(\nu\)</span> governs how tightly the <span class="math inline">\(\pi_k\)</span> are concentrated around <span class="math inline">\(\lambda\)</span>, with larger values implying
greater concentration. We do not place any constraints on <span class="math inline">\(\lambda\)</span>, except to restrict it to the
range <span class="math inline">\(0 &lt; \lambda &lt; 1\)</span>. We
assume that the <span class="math inline">\(\nu\)</span> parameter comes
from a log-normal distribution, <span class="math display">\[\begin{equation}
  \nu \sim \text{LogNormal}(\log 10, 1).
\end{equation}\]</span> The distributional assumptions about <span class="math inline">\(\nu\)</span> have virtually no impact on the
estimates of <span class="math inline">\(\pi_k\)</span>, except when the
number of small areas and the population of each area is small. Placing
a soft constraint on <span class="math inline">\(\nu\)</span> does,
however, help stabilise estimates at reasonable values when counts are
small.</p>
<p>Fitted values for <span class="math inline">\(\lambda\)</span> and
<span class="math inline">\(\nu\)</span> can be obtained by finding the
values that maximise the quantity <span class="math display">\[\begin{equation}
  \prod_{k=1}^K \text{BetaBinom}(x_k | n_k, \lambda \nu, (1 - \lambda)
\nu) \text{LogNormal}(\nu | \log 10, 1).
\end{equation}\]</span> This quantity is proportional to the posterior
distribution, or, in non-Bayesian terms, to the penalised likelihood.
See <span class="citation">Wikipedia contributors (2023a)</span> on the
definition of the beta-binomial distribution. Values for the <span class="math inline">\(\pi_k\)</span> can then be derived using the
properties of the binomial and beta distributions <span class="citation">(Wikipedia contributors 2023b)</span>. The fitted value
for <span class="math inline">\(\pi_k\)</span> is <span class="math display">\[\begin{equation}
  \hat{\pi}_k = \frac{x_k + \lambda \nu}{n_k + \nu} (\#eq:pihat)
\end{equation}\]</span></p>
<p>A smoothed value for the number of people with the attribute is then
<span class="math inline">\(\hat{\pi}_k N_k\)</span>, or, when the data
are a complete enumeration of the population, <span class="math inline">\(\hat{\pi}_k n_k\)</span>.</p>
</div>
<div class="section level3">
<h3 id="partial-pooling">Partial pooling<a class="anchor" aria-label="anchor" href="#partial-pooling"></a>
</h3>
<p>The formula for <span class="math inline">\(\hat{\pi}_k\)</span>
given in @ref(eq:pihat) can be rewritten as <span class="math display">\[\begin{equation}
  \hat{\pi}_k = \phi_k \frac{x_k}{n_k} + (1 - \phi_k) \hat{\lambda}
    (\#eq:partial)
\end{equation}\]</span> where <span class="math display">\[\begin{equation}
  \phi_k = \frac{n_k}{n_k + \hat{\nu}_k}.
\end{equation}\]</span> The quantity <span class="math inline">\(\frac{x_k}{n_k}\)</span> in @ref(eq:partial) is
the traditional ‘direct’ estimate of the probability in area <span class="math inline">\(k\)</span>. The direct estimate is based entirely
on data for area <span class="math inline">\(k\)</span>, with no
smoothing. The parameter <span class="math inline">\(\hat{\lambda}\)</span> is an estimate of the
average value across all areas, and uses all available data. The
parameter <span class="math inline">\(\phi_k\)</span> is type of weight,
which is close to 1 when <span class="math inline">\(n_k\)</span> is
large, and close to 0 when <span class="math inline">\(n_k\)</span> is
small.</p>
<p>Equation @ref(eq:partial) shows how <span class="math inline">\(\hat{\pi}_k\)</span> can be regarded a compromise
between the local estimate <span class="math inline">\(\frac{x_k}{n_k}\)</span> and the global estimate
<span class="math inline">\(\hat{\lambda}\)</span>. The way that the
weights <span class="math inline">\(\phi_k\)</span> are constructed
means that the local estimate exerts greater influence when there is
more data to support it, and less influence when there is less data to
support it. This data-driven balancing of local and global estimates is
common in small area estimation, where it is known, among other things,
as “partial pooling”. Partial pooling makes intuitive sense, and usually
performs well in practice.</p>
<p>A characteristic of partially-pooled estimates is that they are more
tightly concentrated than direct estimates. This is a form of smoothing,
also referred to as shrinkage or regularisation. The estimator in
@ref(eq:partial) has this property. Partial pooling shifts the <span class="math inline">\(\pi_k\)</span> towards <span class="math inline">\(\hat{\lambda}\)</span>, so that they are more
concentrated than the direct estimates <span class="math inline">\(\frac{x_k}{n_k}\)</span>.</p>
</div>
</div>
<div class="section level2">
<h2 id="measurement-error">Measurement error<a class="anchor" aria-label="anchor" href="#measurement-error"></a>
</h2>
<div class="section level3">
<h3 id="setting">Setting<a class="anchor" aria-label="anchor" href="#setting"></a>
</h3>
<p>A second sort of error that often affects small area estimates is
measurement error. Measurement error can occur, for instance, when
respondents misunderstand the question, when proxy respondents were
used, or when the definitions used in the data are different from the
ones required by the analysis.</p>
<p>Accounting for measurement errors normally requires some sort of
additional data on the true underlying values. Function
<code><a href="../reference/scale_prob.html">scale_prob()</a></code>, the function <strong>smoothscale</strong>
that deals with measurement error, requires reliable data on
national-level prevalences. A typical source of reliable national-level
data is household surveys. Although household surveys do not have large
enough samples to provide stable estimates for small areas, they do
typically have large enough samples to provide stable estimates at the
national level, while also having relatively low measurement errors.</p>
</div>
<div class="section level3">
<h3 id="model">Model<a class="anchor" aria-label="anchor" href="#model"></a>
</h3>
<p>Let <span class="math inline">\(p_k\)</span> be an initial estimate
of the probability that a person in area <span class="math inline">\(k\)</span> possesses the attribute in question. We
think that <span class="math inline">\(p_k\)</span> differs from the
true value <span class="math inline">\(\pi_k\)</span> because of
measurement error, that is, <span class="math display">\[\begin{equation}
  \pi_k = p_k + \epsilon_k,
\end{equation}\]</span> where <span class="math inline">\(\epsilon_k\)</span> is an area-level measurement
error. To estimate <span class="math inline">\(\pi_k\)</span>, we need a
way of estimating <span class="math inline">\(\text{epsilon}_k\)</span>.</p>
<p>Let <span class="math display">\[\begin{equation}
  w_k = \frac{N_k}{\sum_{k=1}^K N_k} \quad \text{or} \quad
\frac{n_k}{\sum_{k=1}^K n_k}, \quad k = 1, \cdots, K,
\end{equation}\]</span> be a known set of population weights. Let <span class="math display">\[\begin{equation}
  \bar{p} = \sum_{k=1}^K w_k p_k
\end{equation}\]</span> be the national-level probability obtained by
averaging the initial area-level estimates, and let <span class="math display">\[\begin{equation}
  \bar{\pi} = \sum_{k=1}^K w_k \pi_k
\end{equation}\]</span> be the true national-level probability.</p>
<p>We can obtain an accurate estimate of <span class="math inline">\(\hat{\pi}\)</span> from, for instance, a
national-level survey, though we do know the individual <span class="math inline">\(\pi_k\)</span>. From the national estimate, we can
calculate the average error, <span class="math display">\[\begin{equation}
  \bar{\epsilon} = \sum_{k=1}^K w_k \epsilon_k = \sum_{k=1}^K w_k (\pi_k
- p_k) = \sum_{k=1}^K w_k \pi_k - \sum_{k=1}^K w_k p_k = \bar{\pi} -
\bar{p}. (\#eq:epsilon)
\end{equation}\]</span></p>
<p>We would like to construct an estimator for <span class="math inline">\(\epsilon_k\)</span> with the form <span class="math display">\[\begin{equation}
  \epsilon_k = \alpha_k \bar{\epsilon}
\end{equation}\]</span> where <span class="math inline">\(\alpha_k\)</span> is an area-specific scaling
factor.</p>
<p>The estimator implemented in <code><a href="../reference/scale_prob.html">scale_prob()</a></code> takes slightly
different forms when the average error is positive (so that we need to
scale upwards) and the average error is negative (so that we need to
scale downwards): <span class="math display">\[\begin{equation}
  \alpha_k = \begin{cases}
    \displaystyle \frac{1 - p_k}{1 - \bar{p}}  &amp; \text{if }
\bar{\epsilon} &gt; 0 \\
    \displaystyle \frac{p_k}{\bar{p}}  &amp; \text{if } \bar{\epsilon}
&lt; 0.
    \end{cases}
\end{equation}\]</span> The scaling factor <span class="math inline">\(\alpha_k\)</span> is irrelevant if <span class="math inline">\(\bar{\epsilon} = 0\)</span>, in which case no
scaling is necessary.</p>
<p>When the national-level error <span class="math inline">\(\bar{\epsilon}\)</span> is positive, the <span class="math inline">\(\alpha_k\)</span> are all non-negative, and <span class="math inline">\(\pi_k\)</span> is always greater than or equal to
<span class="math inline">\(p_k\)</span>. Conversely, when <span class="math inline">\(\bar{\epsilon}\)</span> is negative, the <span class="math inline">\(\alpha_k\)</span> are all non-positive, and <span class="math inline">\(\pi_k\)</span> is always less than than or equal
to <span class="math inline">\(p_k\)</span>.</p>
<p>The <code><a href="../reference/scale_prob.html">scale_prob()</a></code> estimator for <span class="math inline">\(\pi_k\)</span> passes some basic sanity
checks:</p>
<ul>
<li>when adjusting upwards, <span class="math inline">\(\pi_k\)</span>
never exceeds 1,</li>
<li>when adjusting downwards, <span class="math inline">\(\pi_k\)</span>
less never less than 0, and</li>
<li>when adjusting in either direction, the <span class="math inline">\(\epsilon_k\)</span> always sum to <span class="math inline">\(\bar{\epsilon}\)</span> as defined in
@ref(eq:epsilon). (See the Appendix for details.)</li>
</ul>
<p>The estimator also smooths the estimates, relative to the original
<span class="math inline">\(\pi_k\)</span>, pulling them in towards a
central value. When adjusting upwards, the size of each adjustment is
proportional to <span class="math inline">\(1 - p_k\)</span>, implying
that unusually low values get large adjustments, and unusually high
values get small adjustments. When adjusting downwards, the size of each
adjustment is proportional to <span class="math inline">\(p_k\)</span>,
implying that unusually high values get large adjustments, and unusually
low values get small adjustments. The adjustment process pulls extreme
values towards the centre, which is reminiscent of the shrinkage that
occurs under partial pooling. If we assume that being extreme is a
symptom of measurement error, then this smoothing behaviour is, on
average, appropriate.</p>
</div>
</div>
<div class="section level2">
<h2 id="stratification">Stratification<a class="anchor" aria-label="anchor" href="#stratification"></a>
</h2>
<p>Often the data is also disaggregated by subpopulation. For instance,
data disaggregated by age and sex might look like this:</p>
<table class="table">
<colgroup>
<col width="14%">
<col width="14%">
<col width="14%">
<col width="19%">
<col width="38%">
</colgroup>
<thead><tr class="header">
<th>District</th>
<th>Age</th>
<th>Sex</th>
<th align="center">All Children</th>
<th align="center">Children attending school</th>
</tr></thead>
<tbody>
<tr class="odd">
<td>1001</td>
<td>5-9</td>
<td>Female</td>
<td align="center">14</td>
<td align="center">10</td>
</tr>
<tr class="even">
<td>1001</td>
<td>5-9</td>
<td>Male</td>
<td align="center">16</td>
<td align="center">13</td>
</tr>
<tr class="odd">
<td>1001</td>
<td>10-14</td>
<td>Female</td>
<td align="center">28</td>
<td align="center">21</td>
</tr>
<tr class="even">
<td>1001</td>
<td>10-14</td>
<td>Male</td>
<td align="center">25</td>
<td align="center">18</td>
</tr>
<tr class="odd">
<td><span class="math inline">\(\vdots\)</span></td>
<td><span class="math inline">\(\vdots\)</span></td>
<td><span class="math inline">\(\vdots\)</span></td>
<td align="center"><span class="math inline">\(\vdots\)</span></td>
<td align="center"><span class="math inline">\(\vdots\)</span></td>
</tr>
<tr class="even">
<td>1156</td>
<td>5-9</td>
<td>Female</td>
<td align="center">11</td>
<td align="center">15</td>
</tr>
<tr class="odd">
<td>1156</td>
<td>5-9</td>
<td>Male</td>
<td align="center">13</td>
<td align="center">13</td>
</tr>
<tr class="even">
<td>1156</td>
<td>10-14</td>
<td>Female</td>
<td align="center">17</td>
<td align="center">5</td>
</tr>
<tr class="odd">
<td>1156</td>
<td>10-14</td>
<td>Male</td>
<td align="center">13</td>
<td align="center">8</td>
</tr>
</tbody>
</table>
<p>The national-level prevalences required by <code><a href="../reference/scale_prob.html">scale_prob()</a></code>
might like this:</p>
<table class="table">
<thead><tr class="header">
<th>Age</th>
<th>Sex</th>
<th align="center">Percent of children attending school</th>
</tr></thead>
<tbody>
<tr class="odd">
<td>5-9</td>
<td>Female</td>
<td align="center">92</td>
</tr>
<tr class="even">
<td>5-9</td>
<td>Male</td>
<td align="center">91</td>
</tr>
<tr class="odd">
<td>10-14</td>
<td>Female</td>
<td align="center">84</td>
</tr>
<tr class="even">
<td>10-14</td>
<td>Male</td>
<td align="center">82</td>
</tr>
</tbody>
</table>
<p><strong>smoothscale</strong> takes a simple approach to
disaggregated: estimates are constructed completely independently for
each combination of the stratifying variables. For instance, with the
data above, estimates would be constructed separately for 5-9 year old
females, 5-9 year old males, 10-14 year old females, and 10-14 year old
males. Although there might be some gains in accuracy or stability from
sharing information across combinations of variables, this would mean
sacrificing simplicity and usability.</p>
</div>
<div class="section level2">
<h2 id="combinations-of-sampling-and-measurement-error">Combinations of sampling and measurement error<a class="anchor" aria-label="anchor" href="#combinations-of-sampling-and-measurement-error"></a>
</h2>
<p>The derivation of the estimator used by <code><a href="../reference/smooth_prob.html">smooth_prob()</a></code>
refers only to sampling error, and the derivation of the estimator used
by <code><a href="../reference/scale_prob.html">scale_prob()</a></code> refers only to measurement error. What if
data are subject to substantial sampling error <em>and</em> measurement
error?</p>
<p>In principle, there might be advantages to modelling sampling error
and measurement error simultaneously. However, doing so would require
extra assumptions about the nature of the measurement errors, and the
ways that these interacted with sample size.</p>
<p>The recommended approach with <strong>smoothscale</strong> is instead
to use <code><a href="../reference/smooth_prob.html">smooth_prob()</a></code> to deal with sampling error, and then
use <code><a href="../reference/scale_prob.html">scale_prob()</a></code> to deal with measurement error. This
approach is much simpler, and given the difficulty of formulating
assuptions about measurement errors, is probably just as accurate.</p>
</div>
<div class="section level2">
<h2 id="appendix-sanity-checks-for-scale_prob-estimator">Appendix: Sanity checks for <code>scale_prob()</code> estimator<a class="anchor" aria-label="anchor" href="#appendix-sanity-checks-for-scale_prob-estimator"></a>
</h2>
<p>When adjusting upwards, <span class="math inline">\(\pi_k\)</span> is
never greater than 1, since <span class="math display">\[\begin{equation}
  \pi_k = p_k + \frac{1 - p_k}{1 - \bar{p}} (\bar{\pi} - \bar{p}) \le
p_k + \frac{1 - p_k}{1 - \bar{p}} (1 - \bar{p}) = p_k + 1 - p_k = 1.
\end{equation}\]</span> Similarly, when adjusting dowwards, <span class="math inline">\(\pi_k\)</span> is less never than 0, since <span class="math display">\[\begin{equation}
  \pi_k = p_k + \frac{p_k}{\bar{p}} (\bar{\pi} - \bar{p}) \ge p_k +
\frac{p_k}{\bar{p}} (-\bar{p}) = p_k - p_k = 0.
\end{equation}\]</span> In addition, when adusting upwards, <span class="math display">\[\begin{equation}
   \sum_{k=1}^K w_k \epsilon_k = \sum_{k=1}^K w_k \frac{1 - p_k}{1 -
\bar{p}} \bar{\epsilon} = \frac{1 - \bar{p}}{1 - \bar{p}} \bar{\epsilon}
= \bar{\epsilon},
\end{equation}\]</span> and, when adusting downwards, <span class="math display">\[\begin{equation}
   \sum_{k=1}^K w_k \epsilon_k = \sum_{k=1}^K w_k \frac{p_k}{\bar{p}}
\bar{\epsilon} = \frac{\bar{p}}{\bar{p}} \bar{\epsilon} =
\bar{\epsilon},
\end{equation}\]</span> as required.</p>
</div>
<div class="section level2">
<h2 class="unnumbered" id="references">References<a class="anchor" aria-label="anchor" href="#references"></a>
</h2>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-gelman2014bayesian" class="csl-entry">
Gelman, A., J. B. Carlin, H. S. Stern, D. B. and Dunson, A. Vehtari, and
D. B. Rubin. 2014. <em>Bayesian Data Analysis. Third Edition</em>. New
York: Chapman; Hall.
</div>
<div id="ref-rao2015small" class="csl-entry">
Rao, John NK, and Isabel Molina. 2015. <em>Small Area Estimation</em>.
John Wiley &amp; Sons.
</div>
<div id="ref-enwiki:1184063616" class="csl-entry">
Wikipedia contributors. 2023a. <span>“Beta-Binomial Distribution —
<span>Wikipedia</span><span>,</span> the Free Encyclopedia.”</span> <a href="https://en.wikipedia.org/w/index.php?title=Beta-binomial_distribution&amp;oldid=1184063616" class="external-link">https://en.wikipedia.org/w/index.php?title=Beta-binomial_distribution&amp;oldid=1184063616</a>.
</div>
<div id="ref-enwiki:1167875362" class="csl-entry">
———. 2023b. <span>“Conjugate Prior —
<span>Wikipedia</span><span>,</span> the Free Encyclopedia.”</span> <a href="https://en.wikipedia.org/w/index.php?title=Conjugate_prior&amp;oldid=1167875362" class="external-link">https://en.wikipedia.org/w/index.php?title=Conjugate_prior&amp;oldid=1167875362</a>.
</div>
</div>
</div>
  </main><aside class="col-md-3"><nav id="toc"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p></p>
<p>Developed by John Bryant, Tom Wilson.</p>
</div>

<div class="pkgdown-footer-right">
  <p></p>
<p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.0.7.</p>
</div>

    </footer>
</div>

  

  

  </body>
</html>
